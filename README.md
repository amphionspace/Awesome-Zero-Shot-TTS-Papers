# Awesome Zero-Shot TTS Papers ⭐️

## Description
This repository is to collect papers on zero-shot TTS, and the materials will be used for the survey talk at Interspeech 2024. 

You are invited to add your papers by send a pull request. Feel free to give this repository a star if you enjoy the work.


*This repo keeps updating. Come back again around Sep 10-15th.*


## Table of Contents
1. [Classic Adaptation Papers](#adaptation)
2. [Representations Papers](#representation)
3. [Model Architecture Papers](#architecture)
4. [Datasets](#dataset)
5. [Demos](#demo)


----
## Classic adaptation/finetuning approaches <a name="adaptation"></a>

* 2009 [Analysis of speaker adaptation algorithms for HMM-based speech synthesis and a constrained SMAPLR adaptation algorithm](https://ieeexplore.ieee.org/document/4740153)
* 2015 [A study of speaker adaptation for DNN-based speech synthesis](https://www.isca-archive.org/interspeech_2015/wu15b_interspeech.pdf)
* 2016 [Unsupervised speaker adaptation for DNN-based TTS synthesis](https://ieeexplore.ieee.org/document/7472656)
* 2018 [Transfer learning from speaker verification to multispeaker text-to-speech synthesis](https://proceedings.neurips.cc/paper_files/paper/2018/file/6832a7b24bc06775d02b7406880b93fc-Paper.pdf)

## Representations <a name="representation"></a>
* 04/2024: [SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound](https://arxiv.org/abs/2405.00233)
* 10/2023: [High-Fidelity Audio Compression with Improved RVQGAN](https://arxiv.org/abs/2306.06546)
* 10/2022: [High Fidelity Neural Audio Compression (EnCodec)](https://arxiv.org/abs/2210.13438)


## Model Architecture <a name="architecture"></a>

* 07/2024: [CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens](https://arxiv.org/pdf/2407.05407)
* 06/2024: [DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer](https://arxiv.org/pdf/2406.11427)
* 06/2024: [Seed-TTS: A Family of High-Quality Versatile Speech Generation Models](https://arxiv.org/pdf/2406.02430)
* 04/2024: [CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech](https://arxiv.org/abs/2404.02781)
* 03/2024: [NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models
](https://arxiv.org/abs/2403.03100)
* 02/2024: [BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data](https://arxiv.org/abs/2402.08093v1)
* 06/2023: [Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale (Voicebox)](https://arxiv.org/abs/2306.15687)
* 06/2023: [AudioPaLM: A Large Language Model That Can Speak and Listen (AudioPaLM)](https://arxiv.org/abs/2306.12925)
* 01/2023: [Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers (VALL-E)](https://arxiv.org/abs/2301.02111)
* 07/2022 [YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for Everyone](https://proceedings.mlr.press/v162/casanova22a/casanova22a.pdf)


## Datasets <a name="dataset"></a>
[Emilia](https://huggingface.co/datasets/amphion/Emilia-Dataset)
[LibriLight](https://github.com/facebookresearch/libri-light)
[Multilingual LibriSpeech (MLS)](https://www.openslr.org/94/)


## Demos <a name="demo"></a>
[CosyVoice](https://fun-audio-llm.github.io/)
[Natural Speech 3](https://speechresearch.github.io/naturalspeech3/)
[Seed-TTS](https://bytedancespeech.github.io/seedtts_tech_report/)
[YourTTS](https://edresson.github.io/YourTTS/)

